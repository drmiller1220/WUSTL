setwd("C:\\Users\\drmiller1220\\Documents\\GitHub\\WUSTL\\HW1")
debatewords <- read.csv("debatewords.csv", header=TRUE)
debatewords$prop_positive_words <- debatewords$Number.of.positive.words/debatewords$Number.of.non.stop.words
debatewords$prop_negative_words <- debatewords$Number.of.negative.words/debatewords$Number.of.non.stop.words
debatewords$prop_positive_words_lan <- debatewords$Number.of.Lancaster.stemmed.positive.words/debatewords$Number.of.non.stop.words
debatewords$prop_negative_words_lan <- debatewords$Number.of.Lancaster.stemmed.negative.words/debatewords$Number.of.non.stop.words
debatewords$prop_positive_words_port <- debatewords$Number.of.Porter.stemmed.positive.words/debatewords$Number.of.non.stop.words
debatewords$prop_negative_words_port <- debatewords$Number.of.Porter.stemmed.negative.words/debatewords$Number.of.non.stop.words
debatewords$prop_positive_words_snow <- debatewords$Number.of.Snowball.stemmed.positive.words/debatewords$Number.of.non.stop.words
debatewords$prop_negative_words_snow <- debatewords$Number.of.Snowball.stemmed.negative.words/debatewords$Number.of.non.stop.words
layout(matrix(c(1,2,3,4,5,5), nrow=3, byrow=TRUE),
heights = c(0.35,0.35,0.3))
plot(y=debatewords$prop_positive_words[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=19, col="dodgerblue", main = "Positive and Negative Word Proportions",
xlab="Statement Number", ylab="Proportion", ylim=c(0,1), xlim=c(0,167))
points(y=debatewords$prop_negative_words[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=3, col="dodgerblue")
points(y=debatewords$prop_positive_words[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=19, col="forestgreen")
points(y=debatewords$prop_negative_words[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=3, col="forestgreen")
points(y=debatewords$prop_positive_words[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=19, col="firebrick1")
points(y=debatewords$prop_negative_words[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=3, col="firebrick1")
plot(y=debatewords$prop_positive_words_lan[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=19, col="dodgerblue", main = "Positive and Negative Word Proportions\n (Lancaster Stemming)",
xlab="Statement Number", ylab="Proportion", ylim=c(0,1), xlim=c(0,167))
points(y=debatewords$prop_negative_words_lan[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=3, col="dodgerblue")
points(y=debatewords$prop_positive_words_lan[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=19, col="forestgreen")
points(y=debatewords$prop_negative_words_lan[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=3, col="forestgreen")
points(y=debatewords$prop_positive_words_lan[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=19, col="firebrick1")
points(y=debatewords$prop_negative_words_lan[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=3, col="firebrick1")
plot(y=debatewords$prop_positive_words_port[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=19, col="dodgerblue", main = "Positive and Negative Word Proportions\n (Porter Stemming)",
xlab="Statement Number", ylab="Proportion", ylim=c(0,1), xlim=c(0,167))
points(y=debatewords$prop_negative_words_port[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=3, col="dodgerblue")
points(y=debatewords$prop_positive_words_port[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=19, col="forestgreen")
points(y=debatewords$prop_negative_words_port[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=3, col="forestgreen")
points(y=debatewords$prop_positive_words_port[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=19, col="firebrick1")
points(y=debatewords$prop_negative_words_port[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=3, col="firebrick1")
plot(y=debatewords$prop_positive_words_snow[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=19, col="dodgerblue", main = "Positive and Negative Word Proportions\n (Snowball Stemming)",
xlab="Statement Number", ylab="Proportion", ylim=c(0,1), xlim=c(0,167))
points(y=debatewords$prop_negative_words_snow[which(debatewords$Speaker=="OBAMA")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="OBAMA")],
type="p", pch=3, col="dodgerblue")
points(y=debatewords$prop_positive_words_snow[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=19, col="forestgreen")
points(y=debatewords$prop_negative_words_snow[which(debatewords$Speaker=="LEHRER")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="LEHRER")],
type="p", pch=3, col="forestgreen")
points(y=debatewords$prop_positive_words_snow[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=19, col="firebrick1")
points(y=debatewords$prop_negative_words_snow[which(debatewords$Speaker=="ROMNEY")],
x=debatewords$Statement.Number[which(debatewords$Speaker=="ROMNEY")],
type="p", pch=3, col="firebrick1")
par(mar=c(0,0,0,0))
plot(0,0, type="n", axes=FALSE, xlab="", ylab="")
legend(x="center", legend=c("Obama","Romney",
"Lehrer", "Positive", "Negative"), lty=c(1,1,1,0,0),
pch=c(NA,NA,NA,19,3),
col = c("dodgerblue","firebrick1","forestgreen","black","black"))
### Questions
### The plots present the positive and negative word proportions for the different kinds of
### stemming or full word analysis.  Each speaker is color-coded as indicated by the legend,
### and dots represent positive word proportions while crosses represent negative word proportions
### Across the plots, we notice that there are more extreme measured proportions when using
### Lancaster stemming than using the other types of stemming (or no stemming at all).
setwd("C:\\Users\\drmiller1220\\Documents\\GitHub\\WUSTL\\HW2")
unigram_dm <- read.csv("unigram_dm.csv", header=TRUE)
trigram_dm <- read.csv("trigram_dm.csv", header=TRUE)
trigram_dm[,501]
trigram_dm[,500]
trigram_dm[,"Author"]
trigram_dm[,"Statement Author"]
trigram_dm[,"Speaker"]
trigram_dm[,"Statement.Author"]
sessions_u <- unigram_dm[which(unigram_dm$Statement.Author=="Sessions"),]
sessions_u <- subset(sessions_u, select = c(-"Statement Author"))
sessions_u <- subset(sessions_u, drop = c("Statement Author"))
sessions_u <- subset(sessions_u, drop = -c("Statement Author"))
sessions_u <- subset(sessions_u, drop = -"Statement Author")
sessions_u <- subset(sessions_u, drop = -Statement.Author)
sessions_u <- unigram_dm[which(unigram_dm$Statement.Author=="Sessions"),]
sessions_u <- subset(sessions_u, select = -Statement.Author)
nrow(sessions_u)
for(i in 1:nrow(sessions_u)){
sum_words <- sum(sessions_u[i,])
sessions_u[i,] <- sessions_u[i,]/sum_words
}
View(sessions_u)
shelby_u <- unigram_dm[which(unigram_dm$Statement.Author=="shelby"),]
shelby_u <- subset(shelby_u, select = -Statement.Author)
# converting frequency counts to rates
for(i in 1:nrow(shelby_u)){
sum_words <- sum(shelby_u[i,])
shelby_u[i,] <- shelby_u[i,]/sum_words
}
shelby_u <- unigram_dm[which(unigram_dm$Statement.Author=="Shelby"),]
shelby_u <- subset(shelby_u, select = -Statement.Author)
# converting frequency counts to rates
for(i in 1:nrow(shelby_u)){
sum_words <- sum(shelby_u[i,])
shelby_u[i,] <- shelby_u[i,]/sum_words
}
sessions_u_mu <- colmeans(sessions_u)
sessions_u_mu <- colMeans(sessions_u)
sessions_u_var <- apply(sessions_u, 2, FUN = function(x) var(x))
lda_u <- (sessions_u_mu - shelby_u_mu)^2 / (sessions_u_var + shelby_u_var)
sessions_u_mu <- colMeans(sessions_u)
sessions_u_var <- apply(sessions_u, 2, FUN = function(x) var(x))
shelby_u_mu <- colMeans(shelby_u)
shelby_u_var <- apply(shelby_u, 2, FUN = function(x) var(x))
lda_u <- (sessions_u_mu - shelby_u_mu)^2 / (sessions_u_var + shelby_u_var)
sort(lda_u)
lda_u <- (sessions_u_mu - shelby_u_mu) / (sessions_u_var + shelby_u_var)
sort(lda_u)
lda_u_weight_sorted <- rev(sort(lda_u_weight))
lda_u_weight <- (sessions_u_mu - shelby_u_mu) / (sessions_u_var + shelby_u_var)
lda_u_weight_sorted <- rev(sort(lda_u_weight))
lda_u_weight_sorted
lda_u_sessions_topwords <- lda_u_weight[1:10]
lda_u_sessions_topwords
lda_u_shelby_topwords <- lda_u_weight[(length(lda_u_weight)-9):lda_u_weight]
lda_u_shelby_topwords <- lda_u_weight[(length(lda_u_weight)-9):length(lda_u_weight)]
lda_u_shelby_topwords
(length(lda_u_weight)-9)
lda_u_sessions_topwords <- lda_u_weight_sorted[1:10]
lda_u_shelby_topwords <- lda_u_weight_sorted[(length(lda_u_weight_sorted)-9):length(lda_u_weight_sorted)]
lda_u_sessions_topwords
lda_u_shelby_topwords
sessions_t <- trigram_dm[which(trigram_dm$Statement.Author=="Sessions"),]
sessions_t <- subset(sessions_t, select = -Statement.Author)
# converting frequency counts to rates
for(i in 1:nrow(sessions_t)){
sum_words <- sum(sessions_t[i,])
sessions_t[i,] <- sessions_t[i,]/sum_words
}
shelby_t <- trigram_dm[which(trigram_dm$Statement.Author=="Shelby"),]
shelby_t <- subset(shelby_t, select = -Statement.Author)
# converting frequency counts to rates
for(i in 1:nrow(shelby_t)){
sum_words <- sum(shelby_t[i,])
shelby_t[i,] <- shelby_t[i,]/sum_words
}
sessions_t_mu <- colMeans(sessions_t)
sessions_t_var <- apply(sessions_t, 2, FUN = function(x) var(x))
shelby_t_mu <- colMeans(shelby_t)
shelby_t_var <- apply(shelby_t, 2, FUN = function(x) var(x))
lda_t_weight <- (sessions_t_mu - shelby_t_mu) / (sessions_t_var + shelby_t_var)
lda_t_weight_sorted <- rev(sort(lda_t_weight))
lda_t_sessions_topwords <- lda_t_weight_sorted[1:10]
lda_t_shelby_topwords <- lda_t_weight_sorted[(length(lda_t_weight_sorted)-9):length(lda_t_weight_sorted)]
lda_t_sessions_topwords
sessions_t_mu
sessions_t_mu <- colMeans(sessions_t, na.rm = TRUE)
sessions_t_var <- apply(sessions_t, 2, FUN = function(x) var(x))
sessions_t_var <- apply(sessions_t, 2, FUN = function(x) var(x, na.rm = TRUE))
shelby_t_mu <- colMeans(shelby_t, na.rm = TRUE)
shelby_t_var <- apply(shelby_t, 2, FUN = function(x) var(x, na.rm = TRUE))
lda_t_weight <- (sessions_t_mu - shelby_t_mu) / (sessions_t_var + shelby_t_var)
lda_t_weight_sorted <- rev(sort(lda_t_weight))
lda_t_sessions_topwords <- lda_t_weight_sorted[1:10]
lda_t_shelby_topwords <- lda_t_weight_sorted[(length(lda_t_weight_sorted)-9):length(lda_t_weight_sorted)]
lda_t_shelby_topwords
lda_t_sessions_topwords
lda_u_sessions_topwords
lda_u_shelby_topwords
lda_u_sessions_topwords <- lda_u_weight_sorted[1:20]
lda_u_shelby_topwords <- lda_u_weight_sorted[(length(lda_u_weight_sorted)-20):length(lda_u_weight_sorted)]
lda_u_shelby_topwords <- lda_u_weight_sorted[(length(lda_u_weight_sorted)-19):length(lda_u_weight_sorted)]
lda_t_sessions_topwords <- lda_t_weight_sorted[1:20]
lda_t_shelby_topwords <- lda_t_weight_sorted[(length(lda_t_weight_sorted)-19):length(lda_t_weight_sorted)]
stddev_diff_u <- sqrt((sessions_u_var/dim(sessions_u)[1]) + (shelby_u_var/dim(shelby_u)[1]))
diff_means_u <- sessions_u_mu - shelby_u_mu
stand_diff_means_u <- diff_means_u/stddev_diff_u
stand_diff_means_u
stand_diff_means_u_sorted <- rev(sort(stand_diff_means_u))
stand_diff_means_u_sorted
diff_means_u <- sessions_u_mu - shelby_u_mu
stddev_diff_u <- sqrt((sessions_u_var/dim(sessions_u)[1]) + (shelby_u_var/dim(shelby_u)[1]))
stand_diff_means_u <- diff_means_u/stddev_diff_u
stand_diff_means_u_sorted <- rev(sort(stand_diff_means_u))
stand_diff_means_u_sessions_topwords <- stand_diff_means_u_sorted[1:20]
stand_diff_means_u_shelby_topwords <- stand_diff_means_u_sorted[(length(stand_diff_means_u_sorted)-19):length(stand_diff_means_u_sorted)]
stand_diff_means_u_sessions_topwords
stand_diff_means_u_shelby_topwords
lda_t_weight_sorted <- sort(lda_t_weight)
lda_t_sessions_topwords <- lda_t_weight_sorted[1:20]
lda_t_shelby_topwords <- lda_t_weight_sorted[(length(lda_t_weight_sorted)-19):length(lda_t_weight_sorted)]
lda_t_sessions_topwords
lda_t_shelby_topwords <- lda_t_weight_sorted[(length(lda_t_weight_sorted)-19):length(lda_t_weight_sorted)]
stand_diff_means_u_sorted <- rev(sort(stand_diff_means_u))
stand_diff_means_u_sessions_topwords <- stand_diff_means_u_sorted[1:20]
stand_diff_means_u_shelby_topwords <- stand_diff_means_u_sorted[(length(stand_diff_means_u_sorted)-19):length(stand_diff_means_u_sorted)]
stand_diff_means_u_sessions_topwords
stand_diff_means_u_shelby_topwords
diff_means_t <- sessions_t_mu - shelby_t_mu
stddev_diff_t <- sqrt((sessions_t_var/dim(sessions_t)[1]) + (shelby_t_var/dim(shelby_t)[1]))
stand_diff_means_t <- diff_means_t/stddev_diff_t
stand_diff_means_t_sorted <- rev(sort(stand_diff_means_t))
stand_diff_means_t_sessions_topwords <- stand_diff_means_t_sorted[1:20]
stand_diff_means_t_shelby_topwords <- stand_diff_means_t_sorted[(length(stand_diff_means_t_sorted)-19):length(stand_diff_means_t_sorted)]
stand_diff_means_t_sessions_topwords
diff_means_t <- sessions_t_mu - shelby_t_mu
stddev_diff_t <- sqrt((sessions_t_var/dim(sessions_t)[1]) + (shelby_t_var/dim(shelby_t)[1]))
stand_diff_means_t <- diff_means_t/stddev_diff_t
stand_diff_means_t_sorted <- rev(sort(stand_diff_means_t))
stand_diff_means_t_sessions_topwords <- stand_diff_means_t_sorted[1:20]
stand_diff_means_t_shelby_topwords <- stand_diff_means_t_sorted[(length(stand_diff_means_t_sorted)-19):length(stand_diff_means_t_sorted)]
stand_diff_means_t_shelby_topwords
sessions_total_u <- sum(colSums(sessions_u))
sessions_u_total <- sum(colSums(sessions_u))
sessions_u_pi
sessions_u_pi <- colSums(sessions_u + 1) / (sessions_u_total + (dim(sessions_u)[2] - 1))
shelby_u_total <- sum(colSums(shelby_u))
shelby_u_pi <- colSums(shelby_u + 1) / (shelby_u_total + (dim(shelby_u)[2] - 1))
shelby_u_pi
logodds_u <- log(sessions_u_pi / (1-sessions_u_pi)) - log(shelby_u_pi / (1 - shelby_u_pi))
logodds_u
varlogodds_u <- (1/(colSums(sessions_u)+1)) + (1/(colSums(shelby_u)+1))
standardized_logodds_u <- logodds_u / sqrt(varlogodds_u)
sessions_t_total <- sum(colSums(sessions_t))
sessions_t_pi <- colSums(sessions_t + 1) / (sessions_t_total + (dim(sessions_t)[2] - 1))
shelby_t_total <- sum(colSums(shelby_t))
shelby_t_pi <- colSums(shelby_t + 1) / (shelby_t_total + (dim(shelby_t)[2] - 1))
logodds_t <- log(sessions_t_pi / (1-sessions_t_pi)) - log(shelby_t_pi / (1 - shelby_t_pi))
varlogodds_t <- (1/(colSums(sessions_t)+1)) + (1/(colSums(shelby_t)+1))
standardized_logodds_t <- logodds_t / sqrt(varlogodds_t)
sessions_t_total
sessions_t_total <- sum(colSums(sessions_t, na.rm = TRUE))
sessions_t_pi <- colSums(sessions_t + 1, na.rm = TRUE) / (sessions_t_total + (dim(sessions_t)[2] - 1))
shelby_t_total <- sum(colSums(shelby_t, na.rm = TRUE))
shelby_t_pi <- colSums(shelby_t + 1, na.rm = TRUE) / (shelby_t_total + (dim(shelby_t)[2] - 1))
logodds_t <- log(sessions_t_pi / (1-sessions_t_pi)) - log(shelby_t_pi / (1 - shelby_t_pi))
varlogodds_t <- (1/(colSums(sessions_t)+1)) + (1/(colSums(shelby_t)+1))
standardized_logodds_t <- logodds_t / sqrt(varlogodds_t)
sessions_t_pi
logodds_t
varlogodds_t <- (1/(colSums(sessions_t, na.rm = TRUE)+1)) + (1/(colSums(shelby_t, na.rm = TRUE)+1))
standardized_logodds_t <- logodds_t / sqrt(varlogodds_t)
standardized_logodds_u_sorted <- rev(sort(standardized_logodds_u))
standardized_logodds_t_sorted <- rev(sort(standardized_logodds_t))
standardized_logodds_u_sorted
standardized_logodds_u_sessions_topwords <- standardized_logodds_u_sorted[1:20]
standardized_logodds_u_shelby_topwords <- standardized_logodds_u_sorted[(length(standardized_logodds_u_sorted)-19):length(standardized_logodds_u_sorted)]
standardized_logodds_u_sessions_topwords
standardized_logodds_u_shelby_topwords
standardized_logodds_t_sessions_topwords <- standardized_logodds_t_sorted[1:20]
standardized_logodds_t_shelby_topwords <- standardized_logodds_t_sorted[(length(standardized_logodds_t_sorted)-19):length(standardized_logodds_t_sorted)]
standardized_logodds_t_sessions_topwords
c(lda_u_sessions_topwords,lda_u_shelby_topwords)
plot(c(lda_u_sessions_topwords,lda_u_shelby_topwords), 1:20, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="",
main="Top 40 Discriminating unigrams\n using linear discriminant analysis")
plot(c(lda_u_sessions_topwords,lda_u_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="",
main="Top 40 Discriminating unigrams\n using linear discriminant analysis")
plot(c(lda_u_sessions_topwords,lda_u_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating unigrams\n using linear discriminant analysis")
text(c(lda_u_sessions_topwords,lda_u_shelby_topwords), 1:40,
label=names(c(lda_u_sessions_topwords,lda_u_shelby_topwords)), cex=0.6)
plot(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using linear discriminant analysis")
text(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40,
label=names(c(lda_t_sessions_topwords,lda_t_shelby_topwords)), cex=0.6)
plot(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using linear discriminant analysis")
text(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40,
label=names(c(lda_t_sessions_topwords,lda_t_shelby_topwords)), cex=0.5)
plot(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40, pch="", xlim=c(-100,20)
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using linear discriminant analysis")
plot(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40, pch="", xlim=c(-100,20),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using linear discriminant analysis")
text(c(lda_t_sessions_topwords,lda_t_shelby_topwords), 1:40,
label=names(c(lda_t_sessions_topwords,lda_t_shelby_topwords)), cex=0.6)
plot(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating unigrams\n using standard mean difference")
text(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords), 1:40,
label=names(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords)), cex=0.6)
plot(c(stand_diff_means_u_sessions_uopwords, stand_diff_means_u_shelby_uopwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating unigrams\n using standard mean difference")
plot(c(stand_diff_means_u_sessions_topwords, stand_diff_means_u_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating unigrams\n using standard mean difference")
text(c(stand_diff_means_u_sessions_topwords, stand_diff_means_u_shelby_topwords), 1:40,
label=names(c(stand_diff_means_u_sessions_topwords, stand_diff_means_u_shelby_topwords)), cex=0.6)
plot(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords),
1:40, pch="", xlim=c(-100,20),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standard mean difference")
text(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords), 1:40,
label=names(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords)), cex=0.6)
plot(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords),
1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standard mean difference")
text(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords), 1:40,
label=names(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords)), cex=0.6)
plot(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords),
1:40, pch="", xlim=c(-40,20),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standard mean difference")
text(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords), 1:40,
label=names(c(stand_diff_means_t_sessions_topwords, stand_diff_means_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_u_sessions_topwords, standardized_logodds_u_shelby_topwords), 1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating unigrams\n using standardized log odds ratio")
text(c(standardized_logodds_u_sessions_topwords, standardized_logodds_u_shelby_topwords), 1:40,
label=names(c(standardized_logodds_u_sessions_topwords, standardized_logodds_u_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-40,20),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="",
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-5.0, -3.0)
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-5.0, -3.0),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-5.0, 3.0),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-5.0, 1),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-4.0, 1.0),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
plot(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords),
1:40, pch="", xlim=c(-4.0, 0),
xlab="Weight (Sessions <--> Shelby)", ylab="", yaxt="n",
main="Top 40 Discriminating trigrams\n using standardized log odds ratio")
text(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords), 1:40,
label=names(c(standardized_logodds_t_sessions_topwords, standardized_logodds_t_shelby_topwords)), cex=0.6)
sessions_sample <- sessions_t[,sample(1:500, 100)]
shelby_sample <- shelby_t[,sample(1:500, 100)]
sessions_sample <- sessions_t[,sample(1:236, 100)]
shelby_sample <- shelby_t[,sample(1:1102, 100)]
sessions_sample <- sessions_t[,sample(1:236, 100)]
shelby_sample <- shelby_t[,sample(1:1102, 100)]
sessions_sample <- sessions_t[sample(1:236, 100),]
shelby_sample <- shelby_t[sample(1:1102, 100),]
all_sample <- rbind(sessions_sample, shelby_sample)
all_sample <- all_sample[,-c(which(colsums(all_sample)==0))]
all_sample <- all_sample[,-c(which(colSums(all_sample)==0))]
all_sample <- rbind(sessions_sample, shelby_sample)
View(all_sample)
all_sample <- all_sample[,-c(which(colSums(all_sample, na.rm = TRUE)==0))]
